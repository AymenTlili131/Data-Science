{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b5b36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project.coInvestigators.coInvestigator</th>\n",
       "      <th>project.responsibleProgram</th>\n",
       "      <th>project.workLocations.workLocation</th>\n",
       "      <th>project.endDate</th>\n",
       "      <th>project.primaryTas.technologyAreas</th>\n",
       "      <th>project.destinations.destination</th>\n",
       "      <th>project.programManagers.programManager</th>\n",
       "      <th>project.description</th>\n",
       "      <th>project.technologyMaturityCurrent</th>\n",
       "      <th>project.title</th>\n",
       "      <th>...</th>\n",
       "      <th>project.principalInvestigators.principalInvestigator</th>\n",
       "      <th>project.lastUpdated</th>\n",
       "      <th>project.supportingOrganizations.organization.name</th>\n",
       "      <th>project.supportingOrganizations.organization.type</th>\n",
       "      <th>project.library</th>\n",
       "      <th>project.technologyMaturityStart</th>\n",
       "      <th>project.responsibleMissionDirectorateOrOffice</th>\n",
       "      <th>project.id</th>\n",
       "      <th>project.startDate</th>\n",
       "      <th>project.status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Ronnie G Willaert, Farooq Azam, Sandor Kasas,...</td>\n",
       "      <td>Concepts for Ocean Worlds Life Detection Techn...</td>\n",
       "      <td>[California, Nevada]</td>\n",
       "      <td>Nov 2018</td>\n",
       "      <td>[{'code': 8, 'name': 'Science Instruments, Obs...</td>\n",
       "      <td>Others Inside the Solar System</td>\n",
       "      <td>Meagan Thompson</td>\n",
       "      <td>One of the most pressing issues of ocean world...</td>\n",
       "      <td>3</td>\n",
       "      <td>Advancing Nanomotion Sensor Technology to Prov...</td>\n",
       "      <td>...</td>\n",
       "      <td>Alison Murray</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>Board of Regents Nevada System of Higher Educa...</td>\n",
       "      <td>Academic</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>Science Mission Directorate</td>\n",
       "      <td>92297</td>\n",
       "      <td>Dec 2016</td>\n",
       "      <td>Completed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              project.coInvestigators.coInvestigator  \\\n",
       "0  [Ronnie G Willaert, Farooq Azam, Sandor Kasas,...   \n",
       "\n",
       "                          project.responsibleProgram  \\\n",
       "0  Concepts for Ocean Worlds Life Detection Techn...   \n",
       "\n",
       "  project.workLocations.workLocation project.endDate  \\\n",
       "0               [California, Nevada]        Nov 2018   \n",
       "\n",
       "                  project.primaryTas.technologyAreas  \\\n",
       "0  [{'code': 8, 'name': 'Science Instruments, Obs...   \n",
       "\n",
       "  project.destinations.destination project.programManagers.programManager  \\\n",
       "0   Others Inside the Solar System                        Meagan Thompson   \n",
       "\n",
       "                                 project.description  \\\n",
       "0  One of the most pressing issues of ocean world...   \n",
       "\n",
       "   project.technologyMaturityCurrent  \\\n",
       "0                                  3   \n",
       "\n",
       "                                       project.title  ...  \\\n",
       "0  Advancing Nanomotion Sensor Technology to Prov...  ...   \n",
       "\n",
       "   project.principalInvestigators.principalInvestigator project.lastUpdated  \\\n",
       "0                                      Alison Murray             2018-10-10   \n",
       "\n",
       "   project.supportingOrganizations.organization.name  \\\n",
       "0  Board of Regents Nevada System of Higher Educa...   \n",
       "\n",
       "  project.supportingOrganizations.organization.type project.library  \\\n",
       "0                                          Academic                   \n",
       "\n",
       "  project.technologyMaturityStart  \\\n",
       "0                               2   \n",
       "\n",
       "  project.responsibleMissionDirectorateOrOffice  project.id project.startDate  \\\n",
       "0                   Science Mission Directorate       92297          Dec 2016   \n",
       "\n",
       "   project.status  \n",
       "0       Completed  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import helper\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba5c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8accb5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_str=r'.\\Juventus\\Home'\n",
    "os.listdir(path_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8679895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name in os.listdir(path_str):# defining the image path\n",
    "    aux=[str(x) for x in path.glob('*'+str(img_name)+'*\\\\*.png')]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2897514",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(path_str,transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "for tu in range(pngCounter):\n",
    "    image= next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded47eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoccerDataset():#['Atalanta','Benevento','Bologna','Cagliari','Chievo','Crotone','Fiorentina','Genoa','Hellas Verona','Internazionale','Juventus','Lazio','Milan','Napoli','Roma','Sampdoria','Sassuolo','SPAL','Torino','Udinese']\n",
    "    def __init__(self,team_name=\"Juventus\",Verbose=False,transform = transforms.Compose([transforms.ToTensor()])):\n",
    "        #attributes\n",
    "        self.path_str=r'.\\Juventus\\Home'\n",
    "               # self.x = D_images\n",
    "               # self.y = D_labels\n",
    "               # self.n_samples = pngCounter\n",
    "        self.transform=transform\n",
    "               #self.dataloader\n",
    "        # data loading\n",
    "        Results = pd.read_csv(\"Results.csv\")\n",
    "        Results=Results[[\"wyId\",\"gameweek\",\"label\",\"Home\",\"Away\",\"Home Score\",\"Away Score\"]]\n",
    "        D_images=dict() #ID--->images\n",
    "        D_labels=dict() #ID--->label\n",
    "        D_NHeatmaps=dict() #ID---->n_heatmaps\n",
    "        for i in range(len(os.listdir(self.path_str))):\n",
    "            path=Path(self.path_str+\"/\"+os.listdir(self.path_str)[i])\n",
    "            D_NHeatmaps[os.listdir(self.path_str)[i]]=sum(1 for x in path.glob('*') if x.is_file())-5\n",
    "        L_match=list()\n",
    "        path=Path('.\\Juventus\\Home')\n",
    "        dataset = torchvision.datasets.ImageFolder(self.path_str,transform=self.transform)\n",
    "        pngCounter = sum(1 for x in path.glob('**/*.png') if x.is_file()) \n",
    "        print(pngCounter)\n",
    "        self.dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "        for tu in range(pngCounter):\n",
    "            image= next(iter(self.dataloader))\n",
    "            L_match.append(image)\n",
    "            for index in range(len(Results[Results[\"Home\"]==\"Juventus\"][[\"Home Score\",\"Away Score\"]].values)):\n",
    "                for ID in D_NHeatmaps.keys():\n",
    "                    if ((str(Results[Results[\"Home\"]==\"Juventus\"][[\"wyId\"]].values[index][0])==ID) and (tu%D_NHeatmaps[ID]==0)and(tu>0)):\n",
    "                        Result,id_match,TeamName=Results[Results[\"Home\"]==\"Juventus\"][[\"Home Score\",\"Away Score\"]].values[index][0:2],Results[Results[\"Home\"]==\"Juventus\"][[\"wyId\"]].values[index][0],Results[Results[\"Home\"]==\"Juventus\"][[\"Home\"]].values[index][0]#Result,id_match,TeamName\n",
    "                        D_labels[str(id_match)]=list(Result)\n",
    "                        D_images[str(id_match)]=L_match \n",
    "                        L_match.clear()\n",
    "        self.x = D_images\n",
    "        self.y = D_labels\n",
    "        self.z = D_NHeatmaps\n",
    "        self.n_samples = pngCounter\n",
    "    def __getitem__(self, ID):\n",
    "        path = self.path_str\n",
    "        preds = self.x[str(ID)]\n",
    "        trgts = self.y[str(ID)]\n",
    "        sample = { \n",
    "            'predictors' : preds,\n",
    "            'targets' : trgts,\n",
    "            'path': path,\n",
    "          }\n",
    "        return preds,trgts\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Foot=SoccerDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1150ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data = Foot[2575964]\n",
    "features, labels = first_data\n",
    "print(features[0][0], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, numChannels, classes):\n",
    "        # call the parent constructor\n",
    "        super(ConvNet, self).__init__()\n",
    "        # initialize first set of CONV => RELU => POOL layers\n",
    "        self.conv1 = nn.Conv3d(in_channels=3, out_channels=20,kernel_size=(5, 5))\n",
    "        \n",
    "        \n",
    "        self.relu1 = ReLU()\n",
    "        \n",
    "        #BRU\n",
    "        self.maxpool1 = nn.MaxPool3d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        \n",
    "        # initialize second set of CONV => RELU => POOL layers\n",
    "        self.conv2 = nn.Conv3d(in_channels=20, out_channels=50,kernel_size=(5, 5))\n",
    "        \n",
    "        self.relu2 = ReLU()\n",
    "        \n",
    "        self.maxpool2 = nn.MaxPool3d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        \n",
    "        # initialize first (and only) set of FC => RELU layers\n",
    "        self.fc1 = Linear(in_features=322560, out_features=500) #322560=480*672\n",
    "        self.relu3 = ReLU()\n",
    "        # initialize our softmax classifier\n",
    "        self.fc2 = Linear(in_features=500, out_features=2)\n",
    "        self.logSoftmax = LogSoftmax(dim=1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # pass the input through our first set of CONV => RELU =>\n",
    "        # POOL layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        # pass the output from the previous layer through the second\n",
    "        # set of CONV => RELU => POOL layers\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        # flatten the output from the previous layer and pass it\n",
    "        # through our only set of FC => RELU layers\n",
    "        x = flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        # pass the output to our softmax classifier to get our output\n",
    "        # predictions\n",
    "        output= self.fc2(x)\n",
    "        #output = self.logSoftmax(x)\n",
    "        # return the output predictions\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fd3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(numChannels,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0193d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training hyperparameters\n",
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 12/19\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78da79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image= next(iter(S.dataloader))\n",
    "id(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b694cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load the dataset\n",
    "print(\"[INFO] loading the Soccer dataset...\")\n",
    "trainData = list(img2Label.items())\n",
    "trainLabel=list(S.y.values())\n",
    "testData =list(img2Label.items()) \n",
    "testLabel=list(S.y.values())\n",
    "# calculate the train/validation split\n",
    "print(\"[INFO] generating the train/validation split...\")\n",
    "numTrainSamples = int(len(trainData) * TRAIN_SPLIT)\n",
    "numValSamples = int(len(trainData) * VAL_SPLIT)\n",
    "trainData, valData = torch.utils.data.random_split(img2Label.items(),[numTrainSamples, numValSamples],generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78856596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the train, validation, and test data loaders\n",
    "trainDataLoader = DataLoader((trainData,trainLabel), shuffle=True,batch_size=BATCH_SIZE)\n",
    "valDataLoader = DataLoader((valData,tra, batch_size=BATCH_SIZE)\n",
    "testDataLoader = DataLoader(testData, batch_size=BATCH_SIZE)\n",
    "# calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainDataLoader.dataset)//BATCH_SIZE\n",
    "valSteps = len(valDataLoader.dataset)//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4939ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ConvNet model\n",
    "print(\"[INFO] initializing the ConvNet model...\")\n",
    "model = ConvNet(numChannels=3,classes=2).to(device)\n",
    "# initialize our optimizer and loss function\n",
    "opt = torch.optim.Adam(model.parameters(), lr=INIT_LR)\n",
    "lossFn = nn.NLLLoss()\n",
    "# initialize a dictionary to store training history\n",
    "H = {\"train_loss\": [],\"train_acc\": [],\"val_loss\": [],\"val_acc\": []}\n",
    "# measure how long training is going to take\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f8189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "# loop over our epochs\n",
    "for e in range(0, EPOCHS):\n",
    "    # set the model in training mode\n",
    "    model.train()\n",
    "    # initialize the total training and validation loss\n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "    # initialize the number of correct predictions in the training\n",
    "    # and validation step\n",
    "    trainCorrect = 0\n",
    "    valCorrect = 0\n",
    "    # loop over the training set\n",
    "    for (x, y) in trainDataLoader:\n",
    "        # send the input to the device\n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        # perform a forward pass and calculate the training loss\n",
    "        pred = model(x)\n",
    "        loss = lossFn(pred, y)\n",
    "        # zero out the gradients, perform the backpropagation step,\n",
    "        # and update the weights\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        # add the loss to the total training loss so far and\n",
    "        # calculate the number of correct predictions\n",
    "        totalTrainLoss += loss\n",
    "        trainCorrect += (pred.argmax(1) == y).type(\n",
    "            torch.float).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "### switch off autograd for evaluation\n",
    "with torch.no_grad():\n",
    "# set the model in evaluation mode\n",
    "    model.eval()\n",
    "    # loop over the validation set\n",
    "    for (x, y) in valDataLoader:\n",
    "        # send the input to the device\n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        # make the predictions and calculate the validation loss\n",
    "        pred = model(x)\n",
    "        totalValLoss += lossFn(pred, y)\n",
    "        # calculate the number of correct predictions\n",
    "        valCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average training and validation loss\n",
    "avgTrainLoss = totalTrainLoss / trainSteps\n",
    "avgValLoss = totalValLoss / valSteps\n",
    "# calculate the training and validation accuracy\n",
    "trainCorrect = trainCorrect / len(trainDataLoader.dataset)\n",
    "valCorrect = valCorrect / len(valDataLoader.dataset)\n",
    "# update our training history\n",
    "H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "H[\"train_acc\"].append(trainCorrect)\n",
    "H[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "H[\"val_acc\"].append(valCorrect)\n",
    "# print the model training and validation information\n",
    "print(\"[INFO] EPOCH: {}/{}\".format(e + 1, EPOCHS))\n",
    "print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(avgTrainLoss, trainCorrect))\n",
    "print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(avgValLoss, valCorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659487e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish measuring how long training took\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))\n",
    "# we can now evaluate the network on the test set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "# turn off autograd for testing evaluation\n",
    "with torch.no_grad():\n",
    "    # set the model in evaluation mode\n",
    "    model.eval()\n",
    "    # initialize a list to store our predictions\n",
    "    preds = []\n",
    "    # loop over the test set\n",
    "    for (x, y) in testDataLoader:\n",
    "        # send the input to the device\n",
    "        x = x.to(device)\n",
    "        # make the predictions and add them to the list\n",
    "        pred = model(x)\n",
    "        preds.extend(pred.argmax(axis=1).cpu().numpy())\n",
    "# generate a classification report\n",
    "print(classification_report(testData.targets.cpu().numpy(),np.array(preds), target_names=testData.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3706e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(H[\"train_acc\"], label=\"train_acc\")\n",
    "plt.plot(H[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])\n",
    "# serialize the model to disk\n",
    "torch.save(model, args[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c13a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025b338b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c3d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05a67b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36workshop",
   "language": "python",
   "name": "p36workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
